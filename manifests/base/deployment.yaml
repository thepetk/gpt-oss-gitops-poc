apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: gpt-oss-app
    app.kubernetes.io/managed-by: kustomize
  name: gpt-oss-app
  namespace: gpt-oss
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: gpt-oss-app
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: gpt-oss-app
    spec:
      containers:
      - name: vllm
        image: quay.io/redhat-ai-dev/vllm-openai-ubi9:v0.11.0
        imagePullPolicy: IfNotPresent
        env:
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: huggingface-token
              key: token
        args:
        - "--model=openai/gpt-oss-20b"
        - "--host=0.0.0.0"
        - "--port=8080"
        - "--download-dir=/.cache"
        - "--max-model-len=8192"
        - "--gpu-memory-utilization=0.95"
        ports:
        - containerPort: 8080
        securityContext:
          runAsNonRoot: true
        volumeMounts:
          - name: dshm
            mountPath: /dev/shm
          - name: models-cache
            mountPath: /models-cache
        resources:
          limits:
            nvidia.com/gpu: "1"
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: "2Gi"
        - name: models-cache
          persistentVolumeClaim:
            claimName: gpt-oss-pvc
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule